function [muPosterior,Kposterior,Kjoint]=GPposterior(X,F,Xstar,params)

% X is a training matrix of size d x n (d = number of features, 
%     n=number of training examples)
% F is a 1 x n vector of target values
% xstar is the input test example (let's just allow this to be
%      d x ntest, but in the online learning case, it would
%      be d x 1)
% params: {muPrior, kernelFunction, lambda, }
%      muPrior: d x ntest vector of means obtained from the prior mean
%         function at xstar
%      kernelFunction: function handle to kernel function, e.g. @kernelExp
%      lambda: for noise
%    
%      kernelFunctionParams: parameters for kernel function (not in cell
%      array)
%
% Return:
% muPosterior - expected posterior value of Fstar
% KPosterior - posterior covariance matrix of Fstar

muPrior=params{1};
kernelFunc=params{2}; % should be function handle, e.g. @kernelExp
lambda=params{3};

sigma=params{5};

Q=lambda*lambda*eye(size(X,2));

nstar=size(Xstar,2);
if isempty(muPrior)
    muPrior=repmat(mean(F),1,nstar);
end
if size(muPrior,2)==1
    muPrior=repmat(muPrior,1,nstar);
end

K=kernelFunc(X,X,{sigma})+Q;
rank(K)
k=kernelFunc(X,Xstar,{sigma});
kappa=kernelFunc(Xstar,Xstar,{sigma})+lambda*lambda;
Kjoint=[K,k;k',kappa];

muPosterior=(muPrior'+(k'/K)*F')';
Kposterior=kappa+(k'/K)*k;

end